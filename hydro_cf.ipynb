{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import gridstatusio as grid\n",
    "import os\n",
    "import functools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import API key & hydro data\n",
    "client = grid.GridStatusClient('c6e457c5394b4f9c9617294d52b3c84b')\n",
    "hydro_capacity = pd.read_csv('/Users/peterambiel/Downloads/hydro_resource_capacity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Page 1...Done in 2.18 seconds. \n",
      "Fetching Page 2...Done in 1.72 seconds. Total time: 3.9s. Avg per page: 1.95s\n",
      "Fetching Page 3...Done in 1.61 seconds. Total time: 5.51s. Avg per page: 1.84s\n",
      "Fetching Page 4...Done in 1.92 seconds. Total time: 7.43s. Avg per page: 1.86s\n",
      "Fetching Page 5...Done in 1.52 seconds. Total time: 8.95s. Avg per page: 1.79s\n",
      "Fetching Page 6...Done in 1.45 seconds. Total time: 10.41s. Avg per page: 1.73s\n",
      "Fetching Page 7...Done in 1.38 seconds. Total time: 11.78s. Avg per page: 1.68s\n",
      "Fetching Page 8...Done in 1.79 seconds. Total time: 13.57s. Avg per page: 1.7s\n",
      "Fetching Page 9...Done in 1.62 seconds. Total time: 15.19s. Avg per page: 1.69s\n",
      "Fetching Page 10...Done in 1.64 seconds. Total time: 16.83s. Avg per page: 1.68s\n",
      "Fetching Page 11...Done in 1.76 seconds. Total time: 18.59s. Avg per page: 1.69s\n",
      "Fetching Page 12...Done in 1.75 seconds. Total time: 20.34s. Avg per page: 1.69s\n",
      "Fetching Page 13...Done in 1.11 seconds. Total time: 21.44s. Avg per page: 1.65s\n",
      "\n",
      "Total number of rows: 630931\n"
     ]
    }
   ],
   "source": [
    "df_caiso_mix = client.get_dataset(\n",
    "    dataset=\"caiso_fuel_mix\",\n",
    "    start=None,  \n",
    "    end=None, \n",
    "    tz=\"US/Pacific\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_capacity_filtered = hydro_capacity.loc[:, ['Resource', '2018', '2019', '2020', '2021', '2022']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caiso_mix_filtered = df_caiso_mix.loc[:, ['interval_start_local', 'interval_end_local', 'small_hydro', 'large_hydro']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6l/c86r3_b541d9cy_whdcmmn_40000gn/T/ipykernel_1305/1326116233.py:7: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.assign(mean_hourly_large_hydro=x['large_hydro'].mean(),\n"
     ]
    }
   ],
   "source": [
    "df_caiso_mix_filtered = (df_caiso_mix_filtered\n",
    "    .assign(year = lambda x: x['interval_start_local'].dt.year,\n",
    "        month = lambda x: x['interval_start_local'].dt.month,\n",
    "        day = lambda x: x['interval_start_local'].dt.day, \n",
    "        hour = lambda x: x['interval_start_local'].dt.hour)\n",
    "    .groupby(['year', 'month', 'day', 'hour'])\n",
    "    .apply(lambda x: x.assign(mean_hourly_large_hydro=x['large_hydro'].mean(), \n",
    "        mean_hourly_small_hydro=x['small_hydro'].mean()))\n",
    "    .assign(large_hydro_capacity = 12281, small_hydro_capacity = 1759)\n",
    "    .assign(large_hydro_cf = lambda x: x['mean_hourly_large_hydro']/ x['large_hydro_capacity'], \n",
    "        small_hydro_cf = lambda x: x['mean_hourly_small_hydro']/ x['small_hydro_capacity'])\n",
    "    .reset_index()\n",
    "    .drop_duplicates(subset=['year', 'month', 'day', 'hour'], keep='first') \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/peterambiel/Desktop/good_model/'\n",
    "file_name= 'hydro_capacity_factor.csv'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Write the DataFrame to a CSV file in the specified folder\n",
    "df_caiso_mix_filtered .to_csv(os.path.join(folder_path, file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(2018, 2023))\n",
    "\n",
    "\n",
    "annual_cf = {}\n",
    "\n",
    "for year in years: \n",
    "\n",
    "    df = (df_caiso_mix_filtered\n",
    "    .query('year == @year')\n",
    "    .reset_index()\n",
    "    .assign(index_hours = lambda x: x.index))\n",
    "    annual_cf[str(year)] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df for key, df in annual_cf.items()][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6l/c86r3_b541d9cy_whdcmmn_40000gn/T/ipykernel_1305/1780135071.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'small_hydro_x', 'index_x', 'mean_hourly_small_hydro_x', 'large_hydro_cf_x', 'month_x', 'small_hydro_capacity_x', 'small_hydro_cf_x', 'level_0_x', 'day_x', 'interval_start_local_x', 'hour_x', 'year_x', 'mean_hourly_large_hydro_x', 'large_hydro_capacity_x', 'interval_end_local_x', 'large_hydro_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  new_df = ft.reduce(lambda left, right: pd.merge(left, right, on='index_hours', how='left'), df_list)\n"
     ]
    }
   ],
   "source": [
    "new_df = ft.reduce(lambda left, right: pd.merge(left, right, on='index_hours', how='left'), df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = (new_df\n",
    "    .loc[:, ['index_hours'] + [col for col in new_df.columns if 'cf' in col]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_capacity_factor = (new_df\n",
    "    .assign(large_cf_mean = lambda x: x[[col for col in x.columns if 'large_hydro' in col]].mean(axis=1), \n",
    "        small_cf_mean = lambda x: x[[col for col in x.columns if 'small_hydro' in col]].mean(axis=1))\n",
    "        [['index_hours', 'large_cf_mean', 'small_cf_mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/peterambiel/Desktop/good_model/'\n",
    "file_name= 'hydro_capacity_factor.csv'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Write the DataFrame to a CSV file in the specified folder\n",
    "hydro_capacity_factor.to_csv(os.path.join(folder_path, file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
